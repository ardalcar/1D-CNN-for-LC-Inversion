Best: 0.000817 using {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.2}
-0.002224 (0.000088) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.001}
-0.000300 (0.000126) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.01}
-0.020775 (0.012614) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.1}
0.000817 (0.010088) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.2}
-0.007597 (0.004008) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.3}
-0.168600 (0.068920) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.001}
-0.002267 (0.001394) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.01}
-0.042329 (0.021998) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.1}
-0.073407 (0.016704) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.2}
-0.015160 (0.004452) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.3}
-0.002735 (0.000377) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.001}
-0.064684 (0.020872) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.01}
-0.006199 (0.008583) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.1}
-0.050140 (0.010619) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.2}
-0.083765 (0.003509) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.3}
-0.039129 (0.002260) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.001}
-0.007981 (0.001259) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.01}
-0.011780 (0.011947) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.1}
-0.012891 (0.005428) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.2}
-0.036263 (0.026116) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.3}
-0.202696 (0.038004) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.001}
-0.001152 (0.000700) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.01}
-0.001962 (0.000111) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.1}
-0.000264 (0.000173) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.2}
-0.004982 (0.006498) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.3}
-0.044541 (0.010958) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.001}
-0.056198 (0.055106) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.01}
-0.001906 (0.001405) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.1}
-0.020253 (0.010414) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.2}
-0.115232 (0.143443) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.3}
-0.134335 (0.121510) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.001}
-0.001432 (0.000877) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.01}
-0.001792 (0.000518) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.1}
-0.000260 (0.000183) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.2}
-0.002390 (0.002930) with: {'batch_size': 10, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.3}
-0.013587 (0.000840) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.001}
-0.000292 (0.000134) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.01}
-0.004872 (0.004857) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.1}
-0.007228 (0.000634) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.2}
-0.010176 (0.006399) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.3}
-0.107472 (0.023841) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.001}
-0.004409 (0.004676) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.01}
-0.191991 (0.157854) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.1}
-0.067207 (0.019581) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.2}
-0.063074 (0.024347) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.3}
-0.004898 (0.001642) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.001}
-0.008082 (0.005698) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.01}
-0.014603 (0.013057) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.1}
-0.028478 (0.024966) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.2}
-0.084458 (0.001338) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.3}
-0.042255 (0.001918) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.001}
-0.017324 (0.001878) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.01}
-0.000997 (0.000275) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.1}
-0.002841 (0.000558) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.2}
-0.018224 (0.008826) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.3}
-0.178562 (0.025357) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.001}
-0.000891 (0.000454) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.01}
-0.000291 (0.000127) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.1}
-0.274583 (0.088735) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.2}
-2.785922 (0.418055) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.3}
-0.023858 (0.008785) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.001}
-0.025717 (0.021691) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.01}
-0.092754 (0.018133) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.1}
-0.151766 (0.208405) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.2}
-0.939333 (0.364796) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.3}
-0.231771 (0.027987) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.001}
-0.000653 (0.000596) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.01}
-0.000271 (0.000159) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.1}
-0.045877 (0.013420) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.2}
-0.257237 (0.086581) with: {'batch_size': 25, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.3}
-0.025511 (0.000405) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.001}
-0.000316 (0.000136) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.01}
-0.000485 (0.000200) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.1}
-0.002665 (0.001773) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.2}
-0.006554 (0.004420) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer__lr': 0.3}
-0.033061 (0.015418) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.001}
-0.004481 (0.000131) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.01}
-18.168933 (25.594318) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.1}
-0.088118 (0.043575) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.2}
-72274.331666 (51129.779887) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'optimizer__lr': 0.3}
-0.003800 (0.004293) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.001}
-0.002872 (0.006964) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.01}
-0.059576 (0.004382) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.1}
-0.069391 (0.005565) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.2}
-0.122307 (0.055582) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adagrad.Adagrad'>, 'optimizer__lr': 0.3}
-0.044846 (0.001430) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.001}
-0.022447 (0.001864) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.01}
-0.000919 (0.000336) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.1}
-0.003967 (0.004710) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.2}
-0.010238 (0.004534) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer__lr': 0.3}
-0.163797 (0.013434) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.001}
-0.000276 (0.000170) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.01}
-0.001745 (0.000202) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.1}
-0.600686 (0.118323) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.2}
-1.368508 (1.143320) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__lr': 0.3}
-0.032979 (0.014187) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.001}
-0.021865 (0.016686) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.01}
-0.138692 (0.006137) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.1}
-0.250873 (0.176631) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.2}
-0.690194 (0.032253) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'optimizer__lr': 0.3}
-0.135817 (0.008270) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.001}
-0.013615 (0.018641) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.01}
-0.001368 (0.000026) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.1}
-0.145796 (0.014055) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.2}
-0.356706 (0.258204) with: {'batch_size': 50, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'optimizer__lr': 0.3}
Traceback (most recent call last):
  File "c:\Users\franc\Documents\Mirko\1D-CNN-for-LC-Inversion\CNN_Py2_grid_search.py", line 73, in <module>
    torch.save(net.state_dict(), "modello_addestrato.pth")
AttributeError: 'NeuralNetRegressor' object has no attribute 'state_dict'
PS C:\Users\franc\Documents\Mirko\1D-CNN-for-LC-Inversion> 